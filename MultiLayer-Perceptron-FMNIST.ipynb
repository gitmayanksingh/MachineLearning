{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(NN)Assignment-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vB_ANObLLbkz",
        "colab_type": "code",
        "outputId": "ab280f9f-2b66-4417-afa3-6015bf536462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPeRRdLqLhpC",
        "colab_type": "code",
        "outputId": "42b008e0-54bd-4abc-b285-38bc5af0ac6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oLxYnZPLlkr",
        "colab_type": "code",
        "outputId": "282a3576-9e3c-413c-8fb9-0683963b9f28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# load train and test dataset\n",
        "\n",
        "(trainX, trainY), (testX, testY) = fashion_mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "trainX = trainX.reshape((trainX.shape[0], 28*28*1))\n",
        "testX = testX.reshape((testX.shape[0], 28*28*1))\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 3us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYdSXIBkPSd1",
        "colab_type": "code",
        "outputId": "18923594-9952-4995-8a12-cf2247ef919c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQXEJRVEru9Y",
        "colab_type": "code",
        "outputId": "b3fa2fad-ba7a-4fd5-b9cb-6e1c9043e659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print('trainX.shape',trainX.shape)\n",
        "print('trainY.shape',trainY.shape)\n",
        "print('testX.shape',testX.shape)\n",
        "print('testY.shape',testY.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "trainX.shape (60000, 784)\n",
            "trainY.shape (60000, 10)\n",
            "testX.shape (10000, 784)\n",
            "testY.shape (10000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR__vq-gLp0A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scale pixels\n",
        "# convert from integers to floats\n",
        "train_norm = trainX.astype('float32')\n",
        "test_norm = testX.astype('float32')\n",
        "# normalize to range 0-1\n",
        "train_norm = train_norm / 255.0\n",
        "test_norm = test_norm / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NhHoy7bj585",
        "colab_type": "code",
        "outputId": "7567b4fc-6760-4560-f830-b7f6af3d4093",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_norm.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rwf5I5oLuFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_epochs = 2000\n",
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "n_dim = train_norm.shape[1]\n",
        "n_class = 10 \n",
        "batch_size = 100\n",
        "display_step = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-RpfbBmXODq",
        "colab_type": "code",
        "outputId": "78a65da5-933a-4063-81dc-b21d44135d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "n_dim"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-HOUl23Lx0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of features\n",
        "n_hidden_2 = 256 # 2nd layer number of features\n",
        "n_hidden_3 = 256 # 1st layer number of features\n",
        "n_hidden_4 = 256 # 2nd layer number of features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6j0c70A8L1PE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, n_dim])\n",
        "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
        "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn7bhPpwmaIZ",
        "colab_type": "code",
        "outputId": "b7e4dc31-d7eb-43db-ec70-d9aa62e39451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Placeholder:0' shape=(?, 784) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PE9FZp5L4aZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "def multilayer_perceptron(x, weights, biases):\n",
        "    # Hidden layer [1] with RELU activation\n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    layer_1 = tf.nn.sigmoid(layer_1)\n",
        "    # Hidden layer [2] with RELU activation\n",
        "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "    layer_2 = tf.nn.sigmoid(layer_2)\n",
        "    # Hidden layer [3] with RELU activation\n",
        "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "    layer_3 = tf.nn.sigmoid(layer_3)\n",
        "    # Hidden layer [4] with RELU activation\n",
        "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
        "    layer_4 = tf.nn.sigmoid(layer_4)\n",
        "    # Output layer with linear activation\n",
        "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qy5CUOML8A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
        "    'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
        "    'h3': tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
        "    'h4': tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
        "    'b2': tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
        "    'b3': tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
        "    'b4': tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR8F8uVQL_e0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct model\n",
        "pred = multilayer_perceptron(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDi6SQC8MDjO",
        "colab_type": "code",
        "outputId": "52ef415f-50ef-4469-9473-f165f06bc184",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# Define loss and optimizer\n",
        "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y_))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost_function)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-b551cfbfb8d9>:1: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO5tG0Ntjh6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initializing the variables\n",
        "init = tf.global_variables_initializer()\n",
        "#create an empty list to store the cost history and accuracy history\n",
        "#cost_history = []\n",
        "accuracy_history = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fy8QSjfRMG_h",
        "colab_type": "code",
        "outputId": "122fa90a-81a5-4862-8ff9-418d173c8e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    for epoch in range(training_epochs):\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(optimizer,feed_dict={x:train_norm,y_:trainY})\n",
        "        cost = sess.run(cost_function,feed_dict={x:train_norm,y_:trainY})\n",
        "        cost_history = np.append(cost_history,cost)\n",
        "        correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y_,1))\n",
        "        # Calculate accuracy\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        accuracy = (sess.run(accuracy,feed_dict={x:test_norm,y_:testY}))\n",
        "        #print ('Accuracy -- >',accuracy)\n",
        "        if epoch % 200 == 0:\n",
        "            print('epoch -> ',epoch,'cost -->',cost,'accuracy -->',accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch ->  0 cost --> 12.480889 accuracy --> 0.0992\n",
            "epoch ->  200 cost --> 14.987206 accuracy --> 0.0708\n",
            "epoch ->  400 cost --> 12.18769 accuracy --> 0.0986\n",
            "epoch ->  600 cost --> 18.866968 accuracy --> 0.0998\n",
            "epoch ->  800 cost --> 15.08289 accuracy --> 0.0796\n",
            "epoch ->  1000 cost --> 17.265402 accuracy --> 0.0957\n",
            "epoch ->  1200 cost --> 12.070403 accuracy --> 0.0998\n",
            "epoch ->  1400 cost --> 11.157529 accuracy --> 0.0715\n",
            "epoch ->  1600 cost --> 16.649942 accuracy --> 0.113\n",
            "epoch ->  1800 cost --> 16.623291 accuracy --> 0.0847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtMA4Vgh3j5Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # # Training for Perceptron "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DLWuFJQ1K0O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network Parameters\n",
        "n_hidden_1 = 256 # 1st layer number of features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNUJDkl51Wpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf Graph input\n",
        "x = tf.placeholder(tf.float32, [None, n_dim])\n",
        "y_ = tf.placeholder(tf.float32, [None, n_class])\n",
        "W = tf.Variable(tf.zeros([n_dim,n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D6mx8u_z_x4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameters\n",
        "learning_rate = 0.0001\n",
        "training_epochs = 5000\n",
        "cost_history = np.empty(shape=[1],dtype=float)\n",
        "n_dim = train_norm.shape[1]\n",
        "n_class = 10 \n",
        "batch_size = 100\n",
        "display_step = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75SSdyeEMoFK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create model\n",
        "def singlelayer_perceptron(x, weights, biases):\n",
        "    # Hidden layer \n",
        "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "    \n",
        "    # Output layer with linear activation\n",
        "    out_layer = tf.matmul(layer_1, weights['out']) + biases['out']\n",
        "    return out_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNEFks00xjCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'h1': tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_hidden_1, n_class]))\n",
        "}\n",
        "biases = {\n",
        "    'b1': tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
        "    'out': tf.Variable(tf.truncated_normal([n_class]))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-meAdVyxyDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Construct model\n",
        "pred = singlelayer_perceptron(x, weights, biases)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTg3qmZnx6_9",
        "colab_type": "code",
        "outputId": "a41bb8d2-2d98-446c-f755-c8ae0ab367ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Define loss and optimizer\n",
        "cost_function = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=y_))\n",
        "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost_function)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raG5mkir1fOK",
        "colab_type": "code",
        "outputId": "4da28375-85ea-41f9-b5f1-0d9dede5e414",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "# Launch the graph\n",
        "with tf.Session() as sess:\n",
        "    for epoch in range(training_epochs):\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "        sess.run(optimizer,feed_dict={x:train_norm,y_:trainY})\n",
        "        cost = sess.run(cost_function,feed_dict={x:train_norm,y_:trainY})\n",
        "        cost_history = np.append(cost_history,cost)\n",
        "        correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(y_,1))\n",
        "        # Calculate accuracy\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "        accuracy = (sess.run(accuracy,feed_dict={x:test_norm,y_:testY}))\n",
        "        #print ('Accuracy -- >',accuracy)\n",
        "        if epoch % 200 == 0:\n",
        "            print('epoch -> ',epoch,'cost -->',cost,'accuracy -->',accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch ->  0 cost --> 58.861935 accuracy --> 0.053\n",
            "epoch ->  200 cost --> 49.657993 accuracy --> 0.0732\n",
            "epoch ->  400 cost --> 23.42132 accuracy --> 0.0826\n",
            "epoch ->  600 cost --> 45.585373 accuracy --> 0.0884\n",
            "epoch ->  800 cost --> 47.489532 accuracy --> 0.0153\n",
            "epoch ->  1000 cost --> 66.80616 accuracy --> 0.1019\n",
            "epoch ->  1200 cost --> 41.860115 accuracy --> 0.1214\n",
            "epoch ->  1400 cost --> 47.296833 accuracy --> 0.0506\n",
            "epoch ->  1600 cost --> 41.908028 accuracy --> 0.09\n",
            "epoch ->  1800 cost --> 27.51727 accuracy --> 0.064\n",
            "epoch ->  2000 cost --> 45.600445 accuracy --> 0.0848\n",
            "epoch ->  2200 cost --> 38.3508 accuracy --> 0.1349\n",
            "epoch ->  2400 cost --> 67.690704 accuracy --> 0.1255\n",
            "epoch ->  2600 cost --> 51.667694 accuracy --> 0.1498\n",
            "epoch ->  2800 cost --> 59.045734 accuracy --> 0.0798\n",
            "epoch ->  3000 cost --> 59.798508 accuracy --> 0.1117\n",
            "epoch ->  3200 cost --> 68.00215 accuracy --> 0.1319\n",
            "epoch ->  3400 cost --> 60.970547 accuracy --> 0.0638\n",
            "epoch ->  3600 cost --> 42.49562 accuracy --> 0.0344\n",
            "epoch ->  3800 cost --> 63.23559 accuracy --> 0.0696\n",
            "epoch ->  4000 cost --> 42.606865 accuracy --> 0.1155\n",
            "epoch ->  4200 cost --> 37.66642 accuracy --> 0.104\n",
            "epoch ->  4400 cost --> 53.272762 accuracy --> 0.0126\n",
            "epoch ->  4600 cost --> 51.075596 accuracy --> 0.1216\n",
            "epoch ->  4800 cost --> 62.041225 accuracy --> 0.0774\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgitfgqzHJmj",
        "colab_type": "text"
      },
      "source": [
        "*****************************************************************  THE END ***************************************************************** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxHOuML0HUvR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}